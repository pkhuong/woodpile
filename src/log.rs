use std::collections::BTreeMap;
use std::io::Result;
use std::path::PathBuf;
use std::sync::Arc;

use crate::pile::Pile;
use crate::shard_writer::ShardWriter;

pub type Record = crate::pile_reader::Record;
pub type WriteOptions = crate::shard_writer::ShardWriterOptions;
pub type CacheOptions = crate::pile_reader::PileReaderOptions;

/// A `Log` is the in-memory representation for a log directory, i.e.,
/// for a bag of timestamped pile directories (one per time bucket).
///
/// The in-memory representation maintains a cache of the records on
/// disk, so frequent reads of the same log only have to tail files
/// instead of re-reading bytes that have already been decoded.
///
/// The contents of the log are eventually consistent: recent records
/// may not be visible, and worse, some young records may eventually
/// disappear.  However, all records that disappear will have been
/// generated by a program that errored out (panicked,
/// usually). Assuming record writers must hold a lease, readers can
/// avoid seeing these ghost records by limiting themselves to records
/// older than all potentially conflicting open leases.
#[derive(Clone, Debug)]
pub struct Log {
    log_directory: Arc<PathBuf>,
    piles: BTreeMap<u64, Pile>, // unix timestamp for bucket -> pile
}

/// A `LogWriter` wraps a [`Log`] and exposes only the
/// [`Log::write_or_panic`] method.
///
/// See [`Log`] for documentation.
#[derive(Clone, Debug)]
#[repr(transparent)]
pub struct LogWriter(Log);

/// A `LogReader` wraps a [`Log`] and exposes only the cache update
/// and query methods.
///
/// See [`Log`] for documentation.
#[derive(Clone, Debug)]
#[repr(transparent)]
pub struct LogReader(Log);

impl From<Log> for LogWriter {
    #[inline(always)]
    fn from(value: Log) -> LogWriter {
        LogWriter(value)
    }
}

impl From<Log> for LogReader {
    #[inline(always)]
    fn from(value: Log) -> LogReader {
        LogReader(value)
    }
}

impl Log {
    /// Creates a new [`Log`] object that will access records under `log_directory`.
    #[inline(always)]
    pub fn new(log_directory: Arc<PathBuf>) -> Log {
        Log {
            log_directory,
            piles: BTreeMap::new(),
        }
    }

    /// Creates a new `LogWriter` from the current log.
    #[inline(always)]
    pub fn get_writer(&self) -> LogWriter {
        Log::new(self.log_directory.clone()).into()
    }

    /// Converts a [`Log`] into a write-only [`LogWriter`].
    pub fn into_writer(self) -> LogWriter {
        self.into()
    }

    /// Converts a [`Log`] into a read-only [`LogReader`].
    pub fn into_reader(self) -> LogReader {
        self.into()
    }

    /// Returns the underlying log directory.
    pub fn log_directory(&self) -> &Arc<PathBuf> {
        &self.log_directory
    }

    /// Attempts to insert a new record in the log.
    ///
    /// The `filename` determines the target file in the pile
    /// directory; it must be unique for the thread, to avoid
    /// interleaved records.
    ///
    /// The `logical_id` is the logical identifier for the record;
    /// that's passed straight through to the application.
    ///
    /// The `now_provider` returns the current time as a [`crate::VouchedTime`].
    /// The current time must track real time; the first call determines the
    /// record's timestamp.
    ///
    /// If we manage to open an output file in the log, `populate` is called
    /// with the [`ShardWriter`]; the bytes written to the [`std::io::Write`]
    /// are the record's contents.
    ///
    /// If `populate` returns `Ok`, we then try to commit the record.  The
    /// commit step succeeds if the commit succeed, returns an `Err`or if
    /// the commit definitely failed, and panics if I/O during the commit
    /// was so slow that we can't tell if it failed or succeeded.
    pub fn write_or_panic<R>(
        &self,
        filename: impl AsRef<std::ffi::OsStr>,
        logical_id: &[u8; 16],
        mut now_provider: impl FnMut() -> crate::VouchedTime,
        options: WriteOptions,
        populate: impl FnOnce(&dyn std::io::Write) -> Result<R>,
    ) -> Result<R> {
        let mut writer = ShardWriter::open(
            (*self.log_directory).clone(),
            filename,
            logical_id,
            now_provider(),
            options,
        )?;
        let ret = populate(&mut writer)?;
        writer.commit_or_panic_if_unclear(move || now_provider().get_local_time())?;
        Ok(ret)
    }

    /// Handles the simple case of maintaining the read-side cache.
    ///
    /// The cache is updated under the assumption that we care about
    /// records with timestamp between `now` and `now - lookback`.
    ///
    /// This method prunes all caches for piles that only contain
    /// records older than `now - lookback`, then ensures we have
    /// up-to-date caches for all piles that contain records between
    /// `now - lookback` and `now`.
    ///
    /// Errors are destructive, but it's safe to retry the call and
    /// use the [`Log`] once [`Log::maintain_cache`] returns `Ok(())`.
    pub fn maintain_cache(
        &mut self,
        now: crate::VouchedTime,
        lookback: time::Duration,
        options: CacheOptions,
    ) -> Result<()> {
        let lookback = lookback
            .max(time::Duration::ZERO)
            .saturating_add(crate::EPOCH_WRITE_DURATION);
        self.prune_cache(now.get_local_time().saturating_sub(lookback));
        self.update_cache(now.get_local_time(), lookback, now, options)
    }

    /// Drops all cached piles for time buckets older than `prune_before`.
    pub fn prune_cache(&mut self, prune_before: time::PrimitiveDateTime) {
        let prune_before = prune_before.assume_utc().unix_timestamp().max(0) as u64;
        let granularity = crate::EPOCH_PERIOD as u64;
        let prune_before = granularity * (prune_before / granularity);

        // Drop all buckets < prune_before
        while let Some((key, _)) = self.piles.first_key_value() {
            if *key >= prune_before {
                break;
            }

            self.piles.pop_first();
        }
    }

    /// Updates all cache piles for time buckets that overlap with
    /// times from `end - lookback` to `end`.
    ///
    /// Errors are destructive, but it's safe to retry the call and
    /// use the [`Log`] once [`Log::update_cache`] returns `Ok(())`.
    pub fn update_cache(
        &mut self,
        end: time::PrimitiveDateTime,
        lookback: time::Duration,
        now: crate::VouchedTime,
        options: CacheOptions,
    ) -> Result<()> {
        let lookback = lookback
            .max(time::Duration::ZERO)
            .saturating_add(crate::EPOCH_WRITE_DURATION);

        let begin = end.saturating_sub(lookback).assume_utc().unix_timestamp();
        let end = end.assume_utc().unix_timestamp();

        let granularity = crate::EPOCH_PERIOD as i64;
        let begin = (granularity * (begin / granularity)) as u64;
        let end = (granularity * (end / granularity)) as u64;

        for bucket in (begin..=end).step_by(granularity as usize) {
            let entry = self.piles.entry(bucket);

            let pile = entry.or_insert_with(|| {
                let time = match time::OffsetDateTime::from_unix_timestamp(bucket as i64) {
                    Ok(time) => time::PrimitiveDateTime::new(time.date(), time.time()),
                    Err(_) => time::PrimitiveDateTime::MAX,
                };

                Pile::new(self.log_directory.clone(), time)
            });

            pile.update(now, options)?;
        }

        Ok(())
    }

    /// Returns an iterator for the sorted and unique stream of cached
    /// records in the [`Log`] with timestamps in `range`
    pub fn range(
        &self,
        range: impl std::ops::RangeBounds<time::PrimitiveDateTime> + Copy,
    ) -> impl Iterator<Item = &Record> {
        use itertools::Itertools;

        itertools::kmerge(self.piles.values().map(|pile| pile.range(range))).unique()
    }
}

impl LogWriter {
    /// See [`Log::write_or_panic`]
    #[inline(always)]
    pub fn write_or_panic<R>(
        &self,
        filename: impl AsRef<std::ffi::OsStr>,
        logical_id: &[u8; 16],
        now_provider: impl FnMut() -> crate::VouchedTime,
        options: WriteOptions,
        populate: impl FnOnce(&dyn std::io::Write) -> Result<R>,
    ) -> Result<R> {
        self.0
            .write_or_panic(filename, logical_id, now_provider, options, populate)
    }
}

impl LogReader {
    /// See [`Log::maintain_cache`]
    #[inline(always)]
    pub fn maintain_cache(
        &mut self,
        now: crate::VouchedTime,
        lookback: time::Duration,
        options: CacheOptions,
    ) -> Result<()> {
        self.0.maintain_cache(now, lookback, options)
    }

    /// See [`Log::prune_cache`]
    #[inline(always)]
    pub fn prune_cache(&mut self, prune_before: time::PrimitiveDateTime) {
        self.0.prune_cache(prune_before)
    }

    /// See [`Log::update_cache`]
    #[inline(always)]
    pub fn update_cache(
        &mut self,
        end: time::PrimitiveDateTime,
        lookback: time::Duration,
        now: crate::VouchedTime,
        options: CacheOptions,
    ) -> Result<()> {
        self.0.update_cache(end, lookback, now, options)
    }

    /// See [`Log::range`]
    #[inline(always)]
    pub fn range(
        &self,
        range: impl std::ops::RangeBounds<time::PrimitiveDateTime> + Copy,
    ) -> impl Iterator<Item = &Record> {
        self.0.range(range)
    }
}
